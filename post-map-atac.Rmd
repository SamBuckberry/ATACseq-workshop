---
title: "Untitled"
author: "Sam Buckberry"
date: "20/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(GenomicRanges)
library(GenomicAlignments)
library(GenomicFeatures)
library(edgeR)
library(TxDb.Hsapiens.UCSC.hg38.knownGene)


library(UpSetR)
library(stringr)
library(magrittr)
library(ggplot2)
library(ggrepel)
```

### Post-alignment processing
Much of the post-alignment processing is done with `samtools` outside of R. While some of this is possible with the `Rsamtools` package, it is much more efficient to write a short shell script with the following steps. 

- Filter reads of mitochondrial data
- Filter for 'proper' read pairs
- Sort the alignments
- Index the alignments
- Remove PCR duplicates

Here are the lines of code for each step:

Remove mitochondrial mapped reads
```{bash, eval=FALSE}
samtools idxstats my_atac.bam | cut -f 1 | grep -v chrM | xargs samtools view -b my_atac.bam > my_atac_filtered.bam

```

Remove reads mapped to blacklisted regions
http://mitra.stanford.edu/kundaje/akundaje/release/blacklists/

Sort the alignments
```{bash, eval=FALSE}
samtools sort my_atac_filtered.bam > my_atac_filtered_sorted.bam
```

Index the sorted alignments
```{bash, eval=FALSE}
samtools index my_atac_filtered_sorted.bam
```

Remove PCR duplicates
```{bash, eval=FALSE}
samtools dedup my_atac_filtered_sorted.bam > my_atac_dedup.bam
```

And we can put that all together in a shell script like this
```{bash, eval=FALSE}
#!/bin/bash

# File inputs
bam=$1
blacklist=$2

prefix=$(basename "$bam" .bam)

# Filter for nuclear genome
samtools idxstats "$bam" | cut -f 1 | grep -v \* | grep -v MT | grep -v chrM | xargs samtools view -b "$bam" > "$prefix"_nuclear.bam

# Remove blacklisted mapped reads
samtools view -L "$blacklist" -U "$prefix"_filtered.bam -b "$prefix"_nuclear.bam > "$prefix".blacklist.bam

# Sort the BAM file
samtools sort "$prefix"_filtered.bam > "$prefix"_sorted.bam

# Index the sorted alignments
samtools index "$prefix"_sorted.bam

# Remove the PCR duplicates
samtools rmdup "$prefix"_sorted.bam "$prefix"_dedup.bam

# Index the dedup BAM file
samtools index "$prefix"_dedup.bam

# Clean up the intermediate files
rm "$prefix"_filtered.bam "$prefix"_sorted.bam "$prefix"_sorted.bam.bai "$prefix".blacklist.bam 

```

Process all alignments with the bash script
```{bash}


```


List the BAM files
```{r}
bam_list <- list.files("aligned_data/", pattern = "filt_fastp.bam$",
                       full.names = TRUE)

ids <- basename(bam_list) %>% str_remove_all("_filt_fastp.bam") %>%
    str_remove_all("Effector_")
```

Plot insert sizes for each library
```{r}

plot_insert_sizes <- function(bam_file, title="") {
    
    # Check if BAM file is paired end
    stopifnot(testPairedEndBam(file = bam_file))
    
    # Setup the filtering parameters for the BAM file
    param <- ScanBamParam(what=c('isize'),
                          flag = scanBamFlag(isSecondaryAlignment = FALSE,
                                             isUnmappedQuery=FALSE,
                                             isNotPassingQualityControls = FALSE))
    
    # Get the insert sizes from the bam file and tabulate
    isize <- scanBam(bam_file, param=param) %>%
        unlist(use.names = FALSE) %>% abs() %>% table()
    
    df <- data.frame(x = as.numeric(names(isize)), y = as.numeric(isize))
    
    # Limit width to 1000 bases for plotting
    df <- df[df$x < 1000, ]
    
    gg_insert <- ggplot(df, aes(x = x, y = y)) + 
        geom_line() + 
        xlab("Fragment length (bp)") +
        ylab("Fragment counts") +
        ggtitle(title) +
        theme_bw()
    
    return(gg_insert)
}


# Plot insert sizes for first BAM file
plot_insert_sizes(bam_list[1])


# Plot all BAMs together
gg_insert_plots <- lapply(1:length(bam_list),
                          function(x){plot_insert_sizes(bam_list[x], ids[x])})

cowplot::plot_grid(plotlist = gg_insert_plots)

```


Plot Tn5 insertions relative to TSS
```{r}

get_tn5_position <- function(bam_file, yield=100000){
    
    message(Sys.time())
    
    # Read the BAM file in chunks to preserve memory
    message(str_c("Reading ", bam_file))
    
    param <- ScanBamParam(flag = scanBamFlag(isPaired = TRUE))
    
    bf <- Rsamtools::BamFile(file = bam_file, yieldSize = yield)
        open(bf)
        gr <- NULL
        repeat {
                chunk <- GenomicAlignments::readGAlignments(bf, param = param)

                if (length(chunk) == 0L)
                        break
                chunk_gr <- GenomicRanges::GRanges(chunk)
                if (is.null(gr)) {
                        gr <- chunk_gr
                } else {
                        gr <- c(gr, chunk_gr)
                }
        }
        close(bf)
    
    message("Offset alignments to Tn5 insertion sites")
    pos <- gr[strand(gr) == "+"] %>% 
        GenomicRanges::shift(shift=4) %>%
        resize(width = 1, fix = "start")
    
    neg <- gr[strand(gr) == "-"] %>%
        GenomicRanges::shift(shift = -5) %>%
        resize(width = 1, fix = "start")
    
    shift_gr <- c(pos, neg)
    strand(shift_gr) <- "+"
    
    return(shift_gr)
}

tn5_grl <- lapply(X = bam_list, FUN = get_tn5_position)

## Get TSS positions
tx <- transcripts(TxDb.Hsapiens.UCSC.hg38.knownGene)
tss <- resize(tx, width = 1, fix = "start")
seqlevelsStyle(tss) <- "Ensembl"
strand(tss) <- "+"


## Calculate distance of Tn5 insertions from TSS
calc_rel_distance <- function(gr1, gr2){
    
    gr2_ind <- GenomicRanges::nearest(x = gr1, subject = gr2,
                                      ignore.strand = TRUE)
    
    dists <- start(gr1) - start(gr2[gr2_ind])
    
    return(dists)

}


all_dists <- lapply(tn5_grl, calc_rel_distance, gr2=tss)

plot_tss_dists <- function(dists, title="", flank=1000){
    
    dists <- dists[abs(dists) <= flank]
    
    df <- table(dists) %>% as.data.frame()
    df$dists <- as.character(df$dists) %>% as.numeric()
    
    gg_dists <- ggplot(df, aes(x = dists, y = Freq)) +
        geom_line() +
        ylab("Frequency") +
        xlab("Distance from TSS") +
        ggtitle(title) +
        theme_bw()
}

tss_dist_plots <- lapply(all_dists, plot_tss_dists)

cowplot::plot_grid(plotlist = tss_dist_plots)

```


Make Tn5 insertion-centered bed files for peak calling, and bigwig files for browser and plotting. 
```{r}

process_atac_bam <- function(bam, yield=100000){
    
    message(Sys.time())
    
    # Read the BAM file in chunks to preserve memory
    message(str_c("Reading ", bam))

    bf <- Rsamtools::BamFile(file = bam, yieldSize = yield)
        open(bf)
        gr <- NULL
        repeat {
                chunk <- GenomicAlignments::readGAlignments(bf)
                if (length(chunk) == 0L)
                        break
                chunk_gr <- GenomicRanges::GRanges(chunk)
                if (is.null(gr)) {
                        gr <- chunk_gr
                } else {
                        gr <- c(gr, chunk_gr)
                }
        }
        close(bf)
    
    message("Offset alignments to Tn5 insertion sites")
    pos <- gr[strand(gr) == "+"] %>% 
        GenomicRanges::shift(shift=4) %>%
        resize(width = 50, fix = "start")
    
    neg <- gr[strand(gr) == "-"] %>%
        GenomicRanges::shift(shift = -5) %>%
        resize(width = 50, fix = "start")
    
    shift_gr <- c(pos, neg)
    strand(shift_gr) <- "+"
    
    message("Calculating coverage")
    cov <- coverage(shift_gr)
    
    # Normalise by sequence depth (CPM)
    message("Normalising by depth")
    lib_size <- length(shift_gr)/1e6
    cov_cpm <- cov / lib_size
    
    # write tn5 centered atac bigwig
    out_bw <- str_replace(string = bam, pattern = ".bam",
                          replacement = "_atac.bw")
    
    message(str_c("Writing ", out_bw))
    
    export.bw(object = cov_cpm, con = out_bw)
    
    # write the tn5 centered bed file for peak calling
    dat <- as.data.frame(shift_gr)[ ,1:3]
    dat$name <- "."
    dat$score <- "."
    dat$strand <- "+"
    
    out_bed <- str_replace(string = bam, pattern = ".bam",
                           replacement = "_atac.bed.gz")
    
    message(str_c("Writing ", out_bed))
    gz1 <- gzfile(out_bed, "w")
    
    write.table(x = dat, file = gz1, quote = FALSE, sep = "\t",
                        row.names = FALSE, col.names = FALSE)
    
    close(gz1)
    
    message(str_c("Completed ", Sys.time()))
        
}

bam_list <- list.files("aligned_data/", pattern = "chr22.bam$",
                       full.names = TRUE)

lapply(bam_list, process_atac_bam)
```



Call peaks for each sample using macs2. This function requires you to have macs2 installed and in your PATH. 
```{r}

atac_bed <- "aligned_data/test.bed.gz"

dir.create("peaks")

call_macs_peaks <- function(atac_bed){
    
    macs_name <- basename(atac_bed) %>% 
        str_remove(pattern = ".bed") %>%
        str_c("peaks/", .)
    
    cmd <- str_c("macs2 callpeak --gsize hs --nomodel --keep-dup all --name ",
                 macs_name, " -t ", atac_bed)
    
    system(cmd)
    
}

# List the atac bed files
atac_bed_list <- list.files("aligned_data/",
                            pattern = ".bed.gz$", full.names = TRUE)

# Run the peak calling function for all of the bed files
lapply(atac_bed_list, call_macs_peaks)

```


Plot peak overlaps
```{r}
peak_fls <- list.files("peaks/", pattern = ".narrowPeak", full.names = TRUE)

# Function to read peak files
peak_to_gr <- function(peak_file){
    
    dat <- read.table(peak_file)
    
    gr <- GRanges(seqnames = dat$V1,
                  ranges = IRanges(start = dat$V2, end = dat$V3))
    
    gr$sample <- basename(peak_file) %>% str_remove("_peaks_narrowPeak")
    
    return(gr)
}
```


```{r}
# Make GRangesList of peaks for all samples
peak_grl <- lapply(peak_fls, peak_to_gr) %>% GRangesList()
names(peak_grl) <- basename(peak_fls)

```


How many peaks detected for each sample?
```{r}
lengths(peak_grl)
```

How wide are the peaks?
```{r}
get_peak_widths <- function(x){
    
    peak_widths <- width(peak_grl[[x]]) %>% as.numeric()
    peak_widths <- data.frame(width = peak_widths, id = names(peak_grl[x]))
    return(peak_widths)
}

peak_widths <- lapply(1:length(peak_grl), get_peak_widths) %>%
    do.call(rbind, .)

gg_width_hist <- ggplot(data = peak_widths, aes(x = width)) +
    geom_histogram() + 
    facet_wrap(.~id) + 
    xlab("Peak width") +
    theme_bw()

gg_width_hist
```

How many peaks overlap between samples?
```{r}
# Make a union peak set for comparing overlaps
union_peak_gr <- unlist(peak_grl) %>% GenomicRanges::reduce()

# Count peak overlaps with union peak set
peak_hits <- lapply(peak_grl, function(x){overlapsAny(union_peak_gr, x)})

# Create a matrix of TRUE/FALSE for peak overlaps
peak_hits <- do.call(cbind, peak_hits)
colnames(peak_hits) <- names(peak_grl) %>%
    str_remove("_chr22_atac.gz_peaks.narrowPeak")
rownames(peak_hits) <- as.character(union_peak_gr) 

# Convert the TRUE/FALSE values into 1/0 
peak_hits <- peak_hits + 0

# Convert to data.frame for plotting
peak_hits <- as.data.frame(peak_hits)

# Make un upset plot to visualise peak overlaps between samples
upset(data = peak_hits, ncol(peak_hits), nintersects = 16)

```


This presence/absence calling of peaks does not give us a lot of information, as some samples may have less noise, and more power for detecting peaks. For this reason, it is a good idea to get a normalised measure of reads in peaks, and then compare samples. 

Calculate number of reads (Tn5 insertions) in peaks for each sample using`.bed` fileswe used for the peak calling
```{r}

# Function to calculate read overlaps. Returns a matrix of counts
calc_read_peak_olaps <- function(bed_file_list, peak_set){
    
    
    get_olaps <- function(bed_file){
        
        read_gr <- bed_to_gr(bed_file)
        olaps <- countOverlaps(query = peak_set, subject = read_gr)
        stopifnot(length(olaps) == length(peak_set))
    
        return(olaps)
    }
    
    peak_olaps <- lapply(X = bed_file_list, FUN = get_olaps)

    peak_olaps <- do.call(cbind, peak_olaps)
    
    colnames(peak_olaps) <- basename(bed_file_list)
    
    rownames(peak_olaps) <- as.character(peak_set)
    
    return(peak_olaps)

}

peak_counts <- calc_read_peak_olaps(bed_file_list = atac_bed_list,
                                    peak_set = union_peak_gr)

# Trim down the column names
colnames(peak_counts) <- colnames(peak_counts) %>% str_remove("_chr22_atac.bed.gz")

head(peak_counts)
```


Save the peak counts table
```{r}
dir.create("processed_data")
write.table(x = peak_counts, "processed_data/atac_peak_counts.tsv",
            quote = FALSE, row.names = TRUE, col.names = TRUE, sep = "\t")
```



Calculate reads in peaks and plot
```{r}
peak_count_sums <- colSums(peak_counts)

qplot(y=peak_count_sums, x=names(peak_count_sums), geom="col") +
    coord_flip() + theme_bw()
```

Calculate Fraction of reads in peaks (FRiP) and plot 
```{r}

get_read_counts <- function(x){
    dat <- read.table(atac_bed_list[x])
    return(nrow(dat))
}

lib_sizes <- lapply(1:length(atac_bed_list), get_read_counts) 
lib_sizes <- unlist(lib_sizes)

FRiP <- peak_count_sums / lib_sizes

qplot(y=FRiP, x=names(FRiP), geom="col") +
    coord_flip() + theme_bw()
```

Calculate length-normalised, and library size normalised peak counts for plotting
```{r}
peak_rpkm <- rpkm(peak_counts, gene.length = width(union_peak_gr),
                  log = TRUE, prior.count = 1)

```

Boxplot peak rpkm
```{r}
boxplot(peak_rpkm)
```

Let's check how the samples look in a PCA
```{r}
plot_pca <- function(mat, dim1=1, dim2=2, scale=TRUE){
        
        # Remove incomplete cases
        mat <- mat[complete.cases(mat), ]
        
        # Transpose
        mat <- t(mat)
        
        # Remove low variance features
        #lowVar <- nearZeroVar(mat, saveMetrics = TRUE)
        #message(str_c("Low variance features removed = ", sum(lowVar$nzv)))
        #mat <- mat[ ,!lowVar$nzv]
        
        # Calculate PC's
        pr <- prcomp(x = mat, scale.=scale)
        pc1 <- (summary(pr)$importance[2, dim1] * 100) %>% round(digits = 1)
        pc2 <- (summary(pr)$importance[2, dim2] * 100) %>% round(digits = 1)

        pc1_dat <- pr$x[ ,dim1]
        pc2_dat <- pr$x[ ,dim2]
        samples <- rownames(pr$x)
        
        pca_df <- data.frame(Sample=samples, PC1=pc1_dat, PC2=pc2_dat)
        
        gg_pca <-  ggplot(data = pca_df,
                          mapping = aes(x = PC2, y = PC1, label=Sample)) +
                geom_point(alpha=0.8, size=4) +
                theme_linedraw() +
                theme(panel.grid = element_line(colour = 'grey')) +
                geom_text_repel(data = subset(pca_df, samples %in% samples),
                                point.padding = unit(1, "lines"), size=3) +
                xlab(str_c("PC", dim2, " (", pc2, "%)")) +
                ylab(str_c("PC", dim1, " (", pc1, "%)"))
        gg_pca
}


atac_pca <- plot_pca(peak_rpkm)
atac_pca
```


Here we see some variance in the read count distributions between libraries, and not real clear seperation of treatment groups. 
In these cases, removing peaks with low counts and between-sample normalisaion often helps. 

Filter low-count peaks and plot PCA
```{r}
keep <- filterByExpr(peak_counts)

peak_filt_rpkm <- rpkm(peak_counts[keep, ], gene.length = width(union_peak_gr[keep]),
                  log = TRUE, prior.count = 1)

plot_pca(peak_filt_rpkm)
```

Here we see that PC2 seperates the treatment and control groups. 

And now with quantile normalisation
```{r}
peak_filt_rpkm_norm <- normalizeBetweenArrays(peak_filt_rpkm, method = "quantile")
plot_pca(peak_filt_rpkm_norm)
```

And now, PC1 seperates the treatment and control groups. 


```{r}
sessionInfo()
```

